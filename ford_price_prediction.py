# -*- coding: utf-8 -*-
"""ford_price_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cYxNbxr5B_M6gznwhOgNAcCCxmJctlFV
"""

import pandas as pd
import numpy as np
import seaborn as sns

df = pd.read_csv('ford.csv')
df

df.describe()

df.info()

df.shape

"""Check Number of duplicates data"""

df_remove_Duplicates = pd.DataFrame(df)
df_remove_Duplicates.duplicated().sum()

"""Remove duplicates data"""

df_remove_Duplicates=df_remove_Duplicates.drop_duplicates()
df_remove_Duplicates.duplicated().sum()

df_remove_Duplicates.head()

"""Start using df_copy that already stored clean data without duplicates"""

#make a copy of dataframe - store the removed duplicates into df_copy
df_copy = df_remove_Duplicates.copy()

#convert Categorical Data into Numerical
df_model = pd.get_dummies(df_remove_Duplicates, columns=['model'])

df_model.head()

#convert Categorical Data into Numerical
df_year = pd.get_dummies(df_model, columns=['year'])

df_year.head()

df_transmission = pd.get_dummies(df_year, columns=['transmission'])

df_transmission.head()

df_all_numerical = pd.get_dummies(df_transmission, columns=['fuelType'])

df_all_numerical.head()

#all data has been transformed to numerical is stored here
df_all_numerical.info()

"""Correlation"""

df_corr = df_all_numerical.corr()


import seaborn as sns
import matplotlib.pyplot as plt

# Set the size of the figure
plt.figure(figsize=(25, 18))

# Plot the heatmap with annotations and adjust font size
sns.heatmap(df_corr, annot=True, annot_kws={"size": 8})

# Display the plot
plt.show()

"""Finalized the Correlated Features - Use for Scaled Data"""

df_corrfeatures_scale = df_all_numerical[['year_1996','year_1998','year_2000','year_2002','year_2003','year_2004','year_2005','year_2006','year_2007','year_2008','year_2009','year_2010','year_2011','year_2012','year_2013','year_2014','year_2015','year_2016','year_2017','year_2018','year_2019','year_2020' ,'price','engineSize', 'model_ Edge', 'model_ Focus', 'model_ Galaxy', 'model_ Kuga', 'model_ Mustang', 'model_ Puma', 'model_ S-MAX', 'model_ Tourneo Custom', 'transmission_Automatic', 'transmission_Semi-Auto', 'fuelType_Diesel']].copy()
df_corrfeatures_scale.head()

"""Finalized the Correlated Features - Use for Unscaled Data"""

df_corrfeatures_unscale = df_all_numerical[['year_1996','year_1998','year_2000','year_2002','year_2003','year_2004','year_2005','year_2006','year_2007','year_2008','year_2009','year_2010','year_2011','year_2012','year_2013','year_2014','year_2015','year_2016','year_2017','year_2018','year_2019','year_2020' ,'price','engineSize', 'model_ Edge', 'model_ Focus', 'model_ Galaxy', 'model_ Kuga', 'model_ Mustang', 'model_ Puma', 'model_ S-MAX', 'model_ Tourneo Custom', 'transmission_Automatic', 'transmission_Semi-Auto', 'fuelType_Diesel']].copy()
df_corrfeatures_unscale.head()

"""Features Scaling"""

from sklearn import preprocessing
scaler = preprocessing.MinMaxScaler()
scalerPrice = preprocessing.MinMaxScaler()      #use later for unscale data

df_price = pd.DataFrame()
df_price['price'] = df_corrfeatures_unscale['price'].copy()          #use later for unscale data

scaled=scaler.fit_transform(df_corrfeatures_scale) #apply scaling function into dataframe and save it back into variable scaled
scaledPrice=scalerPrice.fit_transform(df_price) #use later for unscale data
df_scaled = pd.DataFrame(scaled)
df_scaled.columns = df_corrfeatures_scale.columns
df_scaled.head()

df_scaled.describe()

df_scaled.info()

from sklearn.model_selection import train_test_split

X=df_scaled.drop('price', axis=1)
y=df_scaled.price

#training and testing split using all feature
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=50) #stratify only for classification not regression
#random state is use to shuffle the dataset so that the model can learn holistically --> this will improve the accuracy number

X

y

from sklearn.linear_model import LinearRegression
modellr = LinearRegression()
modellr.fit(X_train, y_train) # Training Phase to find m (slope) and c (intercept)

import pickle
pickle.dump(modellr,open("ford_prediction_model.h5","wb"))
print('Model Saved')

y_pred = modellr.predict(X_test) # Testing Phase by giving only X input to predict y. Now the formula y = mX + C is completed. Just need to find value of y
y_pred

from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# The mean absolute error
print("Mean absolute error: {} ".format(mean_absolute_error(y_test, y_pred)))

# The mean squared error
print("Mean squared error: {} ".format(mean_squared_error(y_test, y_pred)))

# Root mean squared error
print("Root mean squared error: {} ".format(mean_squared_error(y_test, y_pred)**0.5))

# Explained variance score: 1 is perfect prediction
print('Variance score: {} '.format(r2_score(y_test,y_pred)))

#compare between actual and prediction

df_prediction = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})
df_prediction

#why the index not sorted? because of Random State

"""Convert into unscaled values"""

tempActual = pd.DataFrame()
tempActual['Actual'] = df_prediction['Actual'].copy()

tempPrediction = pd.DataFrame()
tempPrediction['Predicted'] = df_prediction['Predicted'].copy()

df_prediction['Actual'] = scalerPrice.inverse_transform(tempActual)
df_prediction['Predicted'] = scalerPrice.inverse_transform(tempPrediction)
df_prediction

df_all_numerical.describe()

"""App"""

import streamlit as st
import pandas as pd
import pickle

st.write("""
# Ford Car Price Prediction App

This app predicts the **Price** for type of advertising stratergy!
""")

st.sidebar.header('User Input Parameters')

def user_input_features():
    year = st.sidebar.slider('Year', 1996.0, 2020.0, 1.0) #All Float
    engineSize = st.sidebar.slider('Engine Size', 0.0, 5.0, 1.0)
    mileage = st.sidebar.slider('Mileage', 1.0, 177644.0, 15.0)
    data = {'Year': year,
            'Engine Size': engineSize,
            'Mileage': mileage}
    features = pd.DataFrame(data, index=[0])
    return features

df = user_input_features()

st.subheader('User Input parameters')
st.write(df)

loaded_model = pickle.load(open("ford_prediction_model.h5", "rb"))

prediction = loaded_model.predict(X)

st.subheader('Prediction')
st.write(prediction)